{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from factory.LstmDV import LstmDV as D_VECTOR\n",
    "from factory.MetaDV import MetaDV as D_VECTOR\n",
    "from util.Dataloader import generate_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_uttrs = 200\n",
    "len_crop = 256\n",
    "batch_size = 32\n",
    "num_classes=80\n",
    "use_shuffle = True\n",
    "save_name = \"metadv_vctk80.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_vector = D_VECTOR(num_classes,len_crop).to('cuda:0')\n",
    "optimizer = torch.optim.Adam(d_vector.parameters(), 1e-4) \n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found directory: train_spmel_vctk\n",
      "Processing speaker: p225\n",
      "Processing speaker: p226\n",
      "Processing speaker: p227\n",
      "Processing speaker: p228\n",
      "Processing speaker: p229\n",
      "Processing speaker: p230\n",
      "Processing speaker: p231\n",
      "Processing speaker: p232\n",
      "Processing speaker: p233\n",
      "Processing speaker: p234\n",
      "Processing speaker: p236\n",
      "Processing speaker: p237\n",
      "Processing speaker: p238\n",
      "Processing speaker: p239\n",
      "Processing speaker: p240\n",
      "Processing speaker: p241\n",
      "Processing speaker: p243\n",
      "Processing speaker: p244\n",
      "Processing speaker: p245\n",
      "Processing speaker: p246\n",
      "Processing speaker: p247\n",
      "Processing speaker: p248\n",
      "Processing speaker: p249\n",
      "Processing speaker: p250\n",
      "Processing speaker: p251\n",
      "Processing speaker: p252\n",
      "Processing speaker: p253\n",
      "Processing speaker: p254\n",
      "Processing speaker: p255\n",
      "Processing speaker: p256\n",
      "Processing speaker: p257\n",
      "Processing speaker: p258\n",
      "Processing speaker: p259\n",
      "Processing speaker: p260\n",
      "Processing speaker: p261\n",
      "Processing speaker: p262\n",
      "Processing speaker: p263\n",
      "Processing speaker: p264\n",
      "Processing speaker: p265\n",
      "Processing speaker: p266\n",
      "Processing speaker: p267\n",
      "Processing speaker: p268\n",
      "Processing speaker: p269\n",
      "Processing speaker: p270\n",
      "Processing speaker: p271\n",
      "Processing speaker: p272\n",
      "Processing speaker: p273\n",
      "Processing speaker: p274\n",
      "Processing speaker: p275\n",
      "Processing speaker: p276\n",
      "Processing speaker: p277\n",
      "Processing speaker: p278\n",
      "Processing speaker: p279\n",
      "Processing speaker: p280\n",
      "Processing speaker: p281\n",
      "Processing speaker: p282\n",
      "Processing speaker: p283\n",
      "Processing speaker: p284\n",
      "Processing speaker: p285\n",
      "Processing speaker: p286\n",
      "Processing speaker: p287\n",
      "Processing speaker: p288\n",
      "Processing speaker: p292\n",
      "Processing speaker: p293\n",
      "Processing speaker: p294\n",
      "Processing speaker: p295\n",
      "Processing speaker: p297\n",
      "Processing speaker: p298\n",
      "Processing speaker: p299\n",
      "Processing speaker: p300\n",
      "Processing speaker: p301\n",
      "Processing speaker: p302\n",
      "Processing speaker: p303\n",
      "Processing speaker: p304\n",
      "Processing speaker: p305\n",
      "Processing speaker: p306\n",
      "Processing speaker: p307\n",
      "Processing speaker: p308\n",
      "Processing speaker: p310\n",
      "Processing speaker: p311\n"
     ]
    }
   ],
   "source": [
    "train_loader = generate_dataset(rootDir='train_spmel_vctk',len_crop=len_crop,num_uttrs=num_uttrs, batch_size=batch_size,use_shuffle=use_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVE LOSS --- 4.118798948736751\n",
      "ACC --- 2.2040555222532277\n",
      "AVE LOSS --- 1.8934988835278679\n",
      "ACC --- 30.716949833297733\n",
      "AVE LOSS --- 0.7468184788437451\n",
      "ACC --- 74.9113562585501\n",
      "AVE LOSS --- 0.42847216269549204\n",
      "ACC --- 86.16139521049473\n",
      "AVE LOSS --- 0.377702023088932\n",
      "ACC --- 88.57798110218323\n",
      "AVE LOSS --- 0.26902272501850827\n",
      "ACC --- 91.4271021761521\n",
      "AVE LOSS --- 0.27391697839998147\n",
      "ACC --- 91.36986135837284\n",
      "AVE LOSS --- 0.24939728730960803\n",
      "ACC --- 92.72293561410983\n",
      "AVE LOSS --- 0.2124516866991625\n",
      "ACC --- 92.78148289517874\n",
      "AVE LOSS --- 0.2127936525927747\n",
      "ACC --- 93.7706338691634\n",
      "AVE LOSS --- 0.1619911240413785\n",
      "ACC --- 95.49333102356934\n",
      "AVE LOSS --- 0.19704837337245837\n",
      "ACC --- 93.78504517602873\n",
      "AVE LOSS --- 0.160605061519891\n",
      "ACC --- 95.21050977101083\n",
      "AVE LOSS --- 0.1590234730283127\n",
      "ACC --- 95.75974153014157\n",
      "AVE LOSS --- 0.16342210717608824\n",
      "ACC --- 94.403335851907\n",
      "AVE LOSS --- 0.14702841981368905\n",
      "ACC --- 95.08304406655694\n",
      "AVE LOSS --- 0.16443427308079075\n",
      "ACC --- 95.6521087491015\n",
      "AVE LOSS --- 0.11788091821979513\n",
      "ACC --- 96.72950151917911\n",
      "AVE LOSS --- 0.1435085474020418\n",
      "ACC --- 95.25077803993861\n",
      "AVE LOSS --- 0.12472382857436862\n",
      "ACC --- 96.5449435638345\n",
      "AVE LOSS --- 0.15920715765644083\n",
      "ACC --- 95.06615948697556\n",
      "AVE LOSS --- 0.12537661879049505\n",
      "ACC --- 95.93430363199819\n",
      "AVE LOSS --- 0.10971021306125776\n",
      "ACC --- 97.76086601413124\n",
      "AVE LOSS --- 0.14786309213377535\n",
      "ACC --- 96.62172241874113\n",
      "AVE LOSS --- 0.07968131611842717\n",
      "ACC --- 96.70934686137484\n",
      "AVE LOSS --- 0.09843407966203385\n",
      "ACC --- 96.85631685226355\n",
      "AVE LOSS --- 0.12075758404920206\n",
      "ACC --- 95.72639018562799\n",
      "AVE LOSS --- 0.09965941888718483\n",
      "ACC --- 96.93350536630197\n",
      "AVE LOSS --- 0.12174830385346842\n",
      "ACC --- 95.8505466245684\n",
      "AVE LOSS --- 0.10570789602009908\n",
      "ACC --- 96.99141400384221\n",
      "AVE LOSS --- 0.08966706404873334\n",
      "ACC --- 97.33571574571461\n",
      "AVE LOSS --- 0.0981179010212038\n",
      "ACC --- 97.27925415113044\n",
      "AVE LOSS --- 0.10089511677677579\n",
      "ACC --- 96.93761091468878\n",
      "AVE LOSS --- 0.08818533436107613\n",
      "ACC --- 97.76323663081821\n",
      "AVE LOSS --- 0.08899762219858959\n",
      "ACC --- 97.37168704707716\n",
      "AVE LOSS --- 0.10937268505735762\n",
      "ACC --- 94.72481136643297\n",
      "AVE LOSS --- 0.08320732116958157\n",
      "ACC --- 97.74381009907282\n",
      "AVE LOSS --- 0.09201650679700406\n",
      "ACC --- 97.28430881429205\n",
      "AVE LOSS --- 0.07150976860121934\n",
      "ACC --- 98.01771593277006\n",
      "AVE LOSS --- 0.07495709450184436\n",
      "ACC --- 97.79056351382721\n",
      "AVE LOSS --- 0.1021441926193588\n",
      "ACC --- 96.98122641651928\n",
      "AVE LOSS --- 0.07953578382781844\n",
      "ACC --- 97.64665620555472\n",
      "AVE LOSS --- 0.07423857346019598\n",
      "ACC --- 97.12426658680239\n",
      "AVE LOSS --- 0.07606254777432803\n",
      "ACC --- 97.67430494538281\n",
      "AVE LOSS --- 0.09117841969504405\n",
      "ACC --- 97.21677596905643\n",
      "AVE LOSS --- 0.07069694966913256\n",
      "ACC --- 97.49712313408394\n",
      "AVE LOSS --- 0.08938404406927636\n",
      "ACC --- 97.08486892080188\n",
      "AVE LOSS --- 0.0853358692219926\n",
      "ACC --- 98.24859471028068\n",
      "AVE LOSS --- 0.06914686931755996\n",
      "ACC --- 97.73655508993947\n",
      "AVE LOSS --- 0.0704078371876248\n",
      "ACC --- 98.12697848683536\n"
     ]
    }
   ],
   "source": [
    "early_stop_count = 0\n",
    "early_repeate = 3\n",
    "last_loss = 100.0\n",
    "for epoch in range(epochs):\n",
    "    n_correct,n_total,train_loss,train_acc,counter = 0,0,0,0,0\n",
    "    for data in train_loader:\n",
    "        inputs, targets = data\n",
    "        targets = targets.view(-1).long()\n",
    "        current_sample = inputs.size(0)  \n",
    "        output,_ = d_vector(inputs)\n",
    "        n_correct += (torch.max(output, 1)[1].long().view(targets.size()) == targets).sum().item()\n",
    "        n_total += current_sample\n",
    "        train_acc_temp = 100. * n_correct / n_total\n",
    "        loss = criterion(output, targets)\n",
    "        train_loss += loss.item()\n",
    "        train_acc += train_acc_temp\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        counter += 1\n",
    "    if epoch == 0:\n",
    "        last_loss = (train_loss/counter)\n",
    "    elif last_loss > (train_loss/counter):\n",
    "        last_loss =  train_loss/counter\n",
    "        early_stop_count = 0\n",
    "    else:\n",
    "        last_loss =  train_loss/counter\n",
    "        early_stop_count += 1\n",
    "        \n",
    "        \n",
    "    print(f\"AVE LOSS --- {train_loss/counter}\")\n",
    "    print(f\"ACC --- {train_acc/counter}\")\n",
    "    \n",
    "    if early_stop_count == early_repeate:\n",
    "        print(\"*************************\")\n",
    "        print(f\" Training Stop at epoch --- {epoch}\")\n",
    "        print(f\" Final AVE LOSS --- {train_loss/counter}\")\n",
    "        print(f\" Final ACC --- {train_acc/counter}\")\n",
    "        print(\"*************************\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(d_vector,save_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
